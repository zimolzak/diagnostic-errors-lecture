---
title: Diagnostic Errors and Informatics Solutions for Quality Improvement
author: Andrew Zimolzak, MD, MMSc
institute:
 - zimolzak@bcm.edu
 - 'Disclosure: None'
date: February, 2026
theme: Goettingen
fonttheme: structurebold
colortheme: whale
aspectratio: 169
---




## Objectives

1. tk





# Introduction

## About me

| Yrs | Research activities                 | Clinical activities |
|-----|-------------------------------------|------------------------------|
| 3+1 | n/a                                 |  Internal medicine residency |
| 2+1 | MMSc biomedical informatics         | Outpatient urgent care |
| 4   | VA Boston: Clinical trials           | Hospitalist |
| 5   | BCM & VA Houston: Health services research | Hospitalist |

What is **Clinical research informatics?**

- I make various clinical research studies "go," using existing data.
- "Phenotyping" using electronic health record **(EHR)** data



## Ideas

- problem representation



## IOM figure

FIXME: insert here



## Historical milestones (GRABER)

- 2008: DEM conference
- 2011: SIDM founded
- 2014: Diagnosis (journal) launched
- 2015: IOM report on diagnostic error
- Coalition & funding: AHRQ grants; advocacy for research funding



## Why diagnostic error matters

- ECRI: Dx error = top patient safety concern (2018)
- Notable case: Rory Staunton---missed sepsis after an initial viral gastroenteritis diagnosis
- Definition: Failure to establish an accurate, timely explanation of the patient's health problem(s) or communicate it to the patient



## Challenges with the definition

- "Accurate" and "timely" are often unclear
- Studying diagnosis in real time is hard---gold standards often require hindsight



## Incidence evidence

- Autopsy studies: 10--30% had relevant missed diagnoses
- Limitations: Autopsy populations and time biases



## Types of diagnostic failures

- ~320 cognitive errors cataloged
- Faulty data gathering $\approx$ 14%
- Majority: errors in data synthesis, context failures, premature closure, absent differential



## Satisficing (Herbert A. Simon), CROSKERRY

- Satisficing: stop at "good enough" rather than optimal
- Clinical example: accepting an early plausible diagnosis without full differential



## Cognitive failure & clinical decision making

- Key references: Pat Croskerry; large mortality comparisons (cardiac, cancer, medical error)
- Diagnostic failure as a major patient safety problem (Newman-Toker)



## Six clusters contributing to diagnostic error

- Physician: knowledge, experience, demographics
- Cognitive: personality, open-mindedness, bias tendency
- Decision-maker homeostasis: sleep, mood, cognitive load
- Environment: system design, ergonomics, teams
- Disease: atypical presentations, mimics
- Patient: communication, history accuracy



## Legal and educational implications

- Review of malpractice cases: diagnosis prominent (>200/347)
- Most failures reflect thinking deficits more than pure knowledge gaps
- Teaching needs: not just facts, but how to think



## Common cognitive biases (top examples)

- Anchoring
- Diagnostic momentum
- Confirmation bias
- Unpacking failure
- Search satisficing
- Framing effects



## Where biases occur

- Early process: anchoring, framing
- Throughout: confirmation, premature closure
- Cognitive + affective biases = top sources of failure



## Improving rationality and debiasing

- Concepts: Rationality quotient, collect diverse info, seek nuance
- Dual-process theory: System 1 (pattern recognition) vs.\ System 2 (analytic)
- Debiasing strategies: recognition, metacognition, "think opposite," forcing functions---require practice



## Training & resources

- TACT program (Dalhousie)---debiasing curriculum and exercises




## Systems perspective (SCHIFF)

- Straw man fixes: more lectures, subspecialty care, more checklists---not sufficient
- Real needs: acknowledge errors, reduce blame, improve situational awareness



## Diagnosis Error Evaluation and Research Taxonomy

- DEER elements: access to care, history, physical, tests, follow-up
- Common system issues: incomplete test completion (*e.g.,* colonoscopies ~50% completed after ordering)



## Overlap: system vs.\ cognitive errors

- System problems often create cognitive constraints (time pressure, incomplete data)
- Metrics for diagnostic safety are elusive; culture (nonpunitive) matters



## Situational awareness & high-reliability orgs

- High-reliability organizations: preoccupation with failure, rehearsal of failure scenarios (Reason)



## Practical pitfalls to watch for

- Mistaken attribution (*e.g.,* chest pain labeled stone)
- Ignoring limits of tests (false negatives)
- Atypical presentations
- Anchoring to chronic diagnoses
- Overlook drug/environmental causes



## Heuristics for high-risk presentations

- 4 Rs (rare, rapid, remediable, really bad)
- 4 Cs (continuing exposure, contagious, chronic progressive, confusing)



## Closed-loop vs.\ open-loop thinking

- Closed-loop: plan + contingencies + follow-up
- Open-loop: unverified assumptions, poorer safety



## EHRs and diagnosis---promise vs.\ problems (MEYER)

- HIT potential: better data access, decision support
- Risks: template constraints, altered clinician-patient interaction, alert fatigue, copy/paste, information overload, burnout



## Example: templated notes

- Templates can improve workflow but may reduce face-to-face attention and encourage assumptions (Ebola case example)



## Altered clinician-patient relationship

- Computer use can reduce perceived clinician attention/trust
- Auto-release of results: useful but may lack clinician interpretation or guidance



## Alert fatigue and cognitive effects

- Too many alerts $\to$ desensitization; important alerts may be ignored
- EHRs can both improve and burden situational awareness



## HIT design considerations for safer diagnosis

- Minimize unnecessary templates/alerts
- Support documentation of differential, contingency plans, and urgent flags
- Improve test result interpretation & communication workflows



## Takeaway actions for learners

- Build concise differentials; state likelihoods & contingencies in notes
- Practice metacognition and debiasing routines (*e.g.,* "what would change my mind?")
- Use EHRs to close loops: track tests, communicate results, document follow-up plans








## Thank you!

### Contact me or review materials:

- zimolzak@bcm.edu

- Source for this talk (make corrections/suggestions)--- <https://github.com/zimolzak/diagnostic-errors-lecture>

- All PMIDs in slide references should work as hyperlinks.

- This work Â© 2026 by Andrew Zimolzak is licensed under CC BY-NC-SA 4.0. [Click for license details.](https://creativecommons.org/licenses/by-nc-sa/4.0/)

- Cite using DOI (will insert when DOI available)
